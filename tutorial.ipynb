{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed0f6b2-48b2-46d5-8d98-100ab4abf64a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from quantum_badger import *\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats=['svg'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855835a-60dc-4cdb-ade1-5e7dbb212fac",
   "metadata": {},
   "source": [
    "# Polynomial Time Approximation for Gaussian Boson Sampling using Threshold Detectors\n",
    "<img src=\"images/GBS_main_h.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Quantum computing's information processing can be performed by devices like **Boson Samplers** [1]. Boson Sampler is a non-universal quantum computer based on optics, equipped with single-photon sources at $n$ indistinguishable inputs of an $m$-mode linear interferometer and $m$ photon-counting detectors (where usually $m \\gg n^2$). In other words, this device performs quantum interference of single photons and measures the output samples.  A *sample* is a specific measurement outcome, defined as a vector in the Fock basis $\\vec{s} = (n_1, n_2, \\: ... ,\\: n_m)$, where $n_i$ is a number of came photons in $i$ detector. All possible samples form the effective size of the Hilbert space of the Boson Sampling problem, which is a combination ${m +n - 1 \\choose n} \\sim \\left(\\frac{m}{n}\\right)^n$.  \n",
    "\n",
    "Here we simulate **Gaussian Boson Sampling** (GBS) protocol is an extension of the Boson Sampling problem proposed in 2017 [2]. Gaussian Boson Sampler consists of squeezed light sources $n$ (single-mode squeezed vacuum states), which interfere in a $m-$mode liner-optical network and then are measured using $m$ photon number-resolving or threshold detectors. Our method is applicable currently only to the GBS problem with thershold detection, i.e. samples consist of zeros and ones. \n",
    "\n",
    "Traditional implementations with single-photon sources are limited in scalability. Gaussian boson sampling emerged as an alternative, and recent experiments showcased its **Quantum Advantage** [3](classical computers need exponentially large time to simulate it). However, imperfections like multi-photon collisions when and noise challenge GBS experiments. A new approach, outlined here and described in detail in [4], offers a polynomial-time approximation algorithm for GBS emulation, accounting for threshold detection and multi-photon collisions without considering other sources of error.\n",
    "\n",
    "*It is worth drawing attention to the fact that we calculate absolute probabilities of randomly generated samples and we do not provide samples from the non-classical distribution.*\n",
    "\n",
    "---\n",
    "[1] Aaronson, Scott, and Alex Arkhipov. \"The computational complexity of linear optics.\" Proceedings of the forty-third annual ACM symposium on Theory of computing. 2011.\n",
    "\n",
    "[2] Hamilton, Craig S., et al. \"Gaussian boson sampling.\" Physical review letters 119.17 (2017): 170501.\n",
    "\n",
    "[3] Zhong, Han-Sen, et al. \"Quantum computational advantage using photons.\" Science 370.6523 (2020): 1460-1463.\n",
    "\n",
    "[4] Popova, A. S., and A. N. Rubtsov. \"Cracking the Quantum Advantage threshold for Gaussian Boson Sampling.\" arXiv preprint arXiv:2106.01445 (2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f61746-de67-4770-a164-ce2fa5ce2190",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computing Probabilities with Quantum Badger\n",
    "<img src=\"images/qb_image_2.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "    \n",
    "    \n",
    "Generally speaking, this operation mode needs __the complex GBS matrix__ and __samples__. To get the matrix, you need to initialize the GBS simulator. The samples can be generated from a uniform distribution for a fixed number of clicked detectors, or you can import your own samples. \n",
    "\n",
    "## Initialize the Gaussian Boson Sampling Emulator\n",
    "\n",
    "There are 2 options for the initialization: \n",
    "\n",
    "1) Import parameters of your GBS device, including the interferometer matrix and set the parameters of the input state manually; \n",
    "2) Use a default GBS setup: half of the input states will be filled by squeezed vacuum states, and a random interferometer matrix will be generated.\n",
    "\n",
    "### Option 1: Import parameters of your GBS device\n",
    "\n",
    "__Step 0:__ Create folders for the data.\n",
    "\n",
    "Here, we highly recommend creating the directory for the current data using the `create_path(filename='tutorial.ipynb')` method. This will ensure that all input and output files are appropriately organized in the `/data` directory.\n",
    "\n",
    "__Step 1:__ Set the GBS device parameters, such as \n",
    "\n",
    "* number of modes `m`\n",
    "* number of inputs filled by squeezed states `n`\n",
    "* squeezing parameter of the input squeezed vacuum states `r`\n",
    "\n",
    "__Step 2:__ Import the interferometer matrix \n",
    "\n",
    "You must have a `matrix_U.dat` file for this regime in your directory. Here and further, we record the real part of complex numbers in odd columns, which are tabular separated from the image part in even columns. \n",
    "\n",
    "__Step 3:__ Export the main GBS matrix \n",
    "\n",
    "The result matrix will be saved in a file `GBS_matrix.dat`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8343e2-615f-4e7b-b8d7-1c5c3496e438",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data were exported to /Users/anastasiacertkova/Desktop/Coding/data/21_13-16_06_2023/initial_state.dat\n",
      "Data were exported to /Users/anastasiacertkova/Desktop/Coding/data/21_13-16_06_2023/GBS_matrix.dat\n"
     ]
    }
   ],
   "source": [
    "# Step 0: create foldes for the data\n",
    "\n",
    "#path = create_path(filename='tutorial.ipynb')\n",
    "path = \"/Users/anastasiacertkova/Desktop/Coding/data/21_13-16_06_2023\"\n",
    "\n",
    "# Use the line below this for reproducibility \n",
    "random.seed(42)\n",
    "\n",
    "# Step 1: Set the GBS device parameters\n",
    "\n",
    "#  Number of modes \n",
    "m = 8\n",
    "#  Number of input squeezed states\n",
    "n = round(m/2) \n",
    "#  Squeezing parameter of the input squeezed vacuum states\n",
    "r = 1.6\n",
    "\n",
    "r_, phi_ = input_state(r, m, n) \n",
    "# it creates two lists of parameters you can do this manually, for example \n",
    "# r_ = [r]*n + [0]*(m-n)\n",
    "# phi_ = [0]*m\n",
    "\n",
    "A = set_input(r_, phi_, path)\n",
    "\n",
    "# Step 2: Import the interferometer matrix\n",
    "U = import_interferometer(path, \"/matrix_U.dat\") \n",
    "\n",
    "# Step 3: Export the main GBS matrix \n",
    "M = set_device_parameters(r, A, U, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6c610-b911-4bc6-aadc-04af144578af",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Option 2: Use a default GBS setup\n",
    "\n",
    "__Step 0:__ Create foldes for the data. \n",
    "\n",
    "Here, we highly recommend creating the directory for the current data using the `create_path(filename='tutorial.ipynb')` method. This will ensure that all input and output files are appropriately organized in the `/data` directory.\n",
    "\n",
    "__Step 1:__ Set the GBS device parameters, such as \n",
    "\n",
    "* number of modes `m`\n",
    "* squeezing parameter of the input squeezed vacuum states `r`\n",
    "\n",
    "__Step 2:__ Generate and export the interferometer matrix and GBS matrix\n",
    "\n",
    "In `choose_default_device()` method we use the following default settings: the number of beam splitters is $m^2$ and the number of filled inputs $n=m/2$.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- If you want to experiment with interferometer matrices, you can use\n",
    "`get_random_interferometer(m, n_BS)` method, where `n_BS` is the number of beam splitters. It produces two output files `matrix_U.dat` and `parameters_of_interferometer.dat`. which can be used  `set_device_parameters()` as decribed above. You also can generate interferometer matrix for  `parameters_of_interferometer.dat` specifing the filepath  `get_random_interferometer(m, n_BS, path=path)`. \n",
    "\n",
    "- *You also can import previously generated data using the following command:*\n",
    "\n",
    "  `M, m, n, r, n_cutoff, n_mc, batch_size = import_input(path, \"GBS_matrix.dat\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5364a-b29a-43a5-81c4-835d6b214945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: create foldes for the data\n",
    "\n",
    "#path = create_path(filename='tutorial.ipynb')\n",
    "path = \"/Users/anastasiacertkova/Desktop/Coding/data/21_13-16_06_2023\"\n",
    "\n",
    "# Use the line below this for reproducibility \n",
    "random.seed(42)\n",
    "\n",
    "# Step 1: Set the GBS device parameters\n",
    "#  Number of modes \n",
    "m = 8\n",
    "#  Number of input squeezed states\n",
    "n = round(m/2) \n",
    "#  Squeezing parameter of the input squeezed vacuum states\n",
    "r = 1.6\n",
    "#  Number of beam splitters \n",
    "n_BS = m**2\n",
    "\n",
    "M, U = choose_default_device(m, r, path=path)\n",
    "\n",
    "# or\n",
    "# M, m, n, r, n_cutoff, n_mc, batch_size = import_input(path, \"/GBS_matrix.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efefd57e-f93f-402a-964d-93348e43a733",
   "metadata": {},
   "source": [
    "## Get samples\n",
    "\n",
    "At this stage, you can uniformly generate the `batch_size` number of samples using the `uniform_sampling_tr()` method and export them with `export_samples()`. In `uniform_sampling_tr()` you need to specify the number of clicked detectors `n_clicked` argument such that it would be more than 4 and less than the number of modes. \n",
    "\n",
    "Also, you are able to import previously generated samples using `import_samples()`. The imported file must consist of a collection of binary sequence samples, with each sample starting on a new line, for example\n",
    "\n",
    "```\n",
    "11010100\n",
    "10100011\n",
    "00101101\n",
    "00101110\n",
    "11100001\n",
    "10001011\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd011e-be5a-4a25-ac31-031e912dbc17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1 # must be >=1\n",
    "n_clicked = 8 #!!! more than 4 for computing 4th order approximathon \n",
    "\n",
    "samples = uniform_sampling_tr(batch_size,n_clicked, m)\n",
    "\n",
    "export_samples(samples, path, \"/samples.dat\")\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0735d1d7-79ee-437c-9749-caea9fd0b506",
   "metadata": {},
   "source": [
    "or import previously generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a7b973-064a-4bc7-9a1e-93b34d3a9f83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = import_samples(path, \"/samples.dat\")\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ea50b9-68e7-4f9e-9287-770e241a316a",
   "metadata": {},
   "source": [
    "## Get approximate probabilities\n",
    "\n",
    "Here you can compute *approximate probabilities* of samples for the GBS device. `dict_probabilities` is a dictionary containing unique samples and approximate probabilities for them. \n",
    "\n",
    "The cell below gives a message like `Computation for sample #0 of 10 is completed.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bd4d9ef-77cd-4149-9119-9f22661d7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation for sample #0 of 1 is completed.\n"
     ]
    }
   ],
   "source": [
    "dict_probabilities = compute_probabilities(samples, path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ac138e-e549-4c45-b901-246ded0f2c94",
   "metadata": {},
   "source": [
    "You also can import previously computed results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea7337-d30d-4a7d-94ad-8ff11116f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_probabilities = import_approx_probabilities(path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd13a3-f309-45e4-8936-3526950685bc",
   "metadata": {},
   "source": [
    "## Obtain DataFrame with results\n",
    "\n",
    "To view the result in a more convenient way, we suggest uploading it into a tabular format using [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html). \n",
    "\n",
    "If you have more than 30 `n_clicks` we recommend setting a parameter `exact_prob = False` and not computing exact probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64be224-606d-4f43-afaa-b2ffcad7cc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1 entries, 11111111 to 11111111\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   n_clicks              1 non-null      int64  \n",
      " 1   probability_exact     1 non-null      float64\n",
      " 2   n_counts              1 non-null      int64  \n",
      " 3   probability_approx_2  1 non-null      float64\n",
      " 4   probability_approx_3  1 non-null      float64\n",
      " 5   probability_approx_4  1 non-null      float64\n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 56.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_66df5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_66df5_level0_col0\" class=\"col_heading level0 col0\" >n_clicks</th>\n",
       "      <th id=\"T_66df5_level0_col1\" class=\"col_heading level0 col1\" >probability_exact</th>\n",
       "      <th id=\"T_66df5_level0_col2\" class=\"col_heading level0 col2\" >n_counts</th>\n",
       "      <th id=\"T_66df5_level0_col3\" class=\"col_heading level0 col3\" >probability_approx_2</th>\n",
       "      <th id=\"T_66df5_level0_col4\" class=\"col_heading level0 col4\" >probability_approx_3</th>\n",
       "      <th id=\"T_66df5_level0_col5\" class=\"col_heading level0 col5\" >probability_approx_4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >sample</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_66df5_level0_row0\" class=\"row_heading level0 row0\" >11111111</th>\n",
       "      <td id=\"T_66df5_row0_col0\" class=\"data row0 col0\" >8</td>\n",
       "      <td id=\"T_66df5_row0_col1\" class=\"data row0 col1\" >1.023e-01</td>\n",
       "      <td id=\"T_66df5_row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "      <td id=\"T_66df5_row0_col3\" class=\"data row0 col3\" >1.824e-03</td>\n",
       "      <td id=\"T_66df5_row0_col4\" class=\"data row0 col4\" >1.343e-03</td>\n",
       "      <td id=\"T_66df5_row0_col5\" class=\"data row0 col5\" >1.632e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8c0a4595b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_result_df(samples, M, dict_probabilities, exact_prob = True)\n",
    "dict_format = get_dict_format(df)   \n",
    "\n",
    "df.info()\n",
    "df.style.format(dict_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61c3670-abc3-458d-8d8e-13de66241ae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_clicked' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m n_clicks \u001b[38;5;241m=\u001b[39m \u001b[43mn_clicked\u001b[49m\n\u001b[1;32m      3\u001b[0m mask \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_clicks\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39mn_clicks\n\u001b[1;32m      5\u001b[0m df[mask]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability_exact\u001b[39m\u001b[38;5;124m\"\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability_exact\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m      6\u001b[0m     kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbar\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProbability\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     title\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExact PMF for samples with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_clicks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m clicked detectors\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_clicked' is not defined"
     ]
    }
   ],
   "source": [
    "n_clicks = n_clicked\n",
    "\n",
    "mask = df[\"n_clicks\"]==n_clicks\n",
    "\n",
    "df[mask].sort_values(by=[\"probability_exact\"], ascending=False)[\"probability_exact\"].plot(\n",
    "    kind=\"bar\",\n",
    "    ylabel=\"Probability\",\n",
    "    title= f\"Exact PMF for samples with {n_clicks} clicked detectors\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d273b14-b595-46ff-921f-6c96ef4daaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask].sort_values(by=[\"probability_approx_2\"], ascending=False)[\"probability_approx_2\"].plot(\n",
    "    kind=\"bar\",\n",
    "    ylabel=\"Probability\",\n",
    "    title= f\"Approximate PMF for samples with {n_clicks} clicked detectors\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1a1091-78c5-46ce-b6d8-85d59e0e3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export DataFrame\n",
    "df.to_csv(path + \"/output/samples_probabilities.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b137f-5792-4ec2-bdac-96b690187a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test the approximate probabilities\n",
    "\n",
    "\n",
    "### Relative Weighted Error\n",
    "\n",
    "The **Relative Weighted Error** quantifies the difference between observed and predicted values, considering their respective weights. It is calculated using the following formula:\n",
    "\n",
    "$$\n",
    "RWE = \\frac{1}{n}\\sum_{i=1}^{n} \\left| 1-\\frac{p_i}{q_i} \\right|\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "- \\(n\\) is the number of data points.\n",
    "- \\(w_i\\) represents the weight assigned to the \\(i\\)th data point.\n",
    "- \\(y_i\\) is the observed (actual) value for the \\(i\\)th data point.\n",
    "- \\(\\hat{y}_i\\) is the predicted value for the \\(i\\)th data point.\n",
    "\n",
    "The relative weighted error is expressed as a percentage, representing the weighted average of the absolute differences between observed and predicted values, divided by the weighted average of the observed values.\n",
    "\n",
    "\n",
    "### Total Variation Distance \n",
    "### Fidelity \n",
    "### Cross entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27b0905-8b50-4eb5-8695-e5e2efeb761d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(p_exact, p_exact)</th>\n",
       "      <th>(p_exact, p_appr_2)</th>\n",
       "      <th>(p_exact, p_appr_3)</th>\n",
       "      <th>(p_exact, p_appr_4)</th>\n",
       "      <th>(p_exact, p_uniform)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relative weighted error</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.104168</td>\n",
       "      <td>75.187689</td>\n",
       "      <td>61.703230</td>\n",
       "      <td>25.200126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982176</td>\n",
       "      <td>0.986875</td>\n",
       "      <td>0.984052</td>\n",
       "      <td>0.961832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cosine similarity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total variation distance</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100520</td>\n",
       "      <td>0.101001</td>\n",
       "      <td>0.100712</td>\n",
       "      <td>0.098438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fidelity</th>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          (p_exact, p_exact)  (p_exact, p_appr_2)  \\\n",
       "metric                                                              \n",
       "relative weighted error             0.000000            55.104168   \n",
       "mape                                0.000000             0.982176   \n",
       "cosine similarity                   1.000000             1.000000   \n",
       "total variation distance            0.000000             0.100520   \n",
       "fidelity                            0.010474             0.000187   \n",
       "\n",
       "                          (p_exact, p_appr_3)  (p_exact, p_appr_4)  \\\n",
       "metric                                                               \n",
       "relative weighted error             75.187689            61.703230   \n",
       "mape                                 0.986875             0.984052   \n",
       "cosine similarity                    1.000000             1.000000   \n",
       "total variation distance             0.101001             0.100712   \n",
       "fidelity                             0.000137             0.000167   \n",
       "\n",
       "                          (p_exact, p_uniform)  \n",
       "metric                                          \n",
       "relative weighted error              25.200126  \n",
       "mape                                  0.961832  \n",
       "cosine similarity                     1.000000  \n",
       "total variation distance              0.098438  \n",
       "fidelity                              0.000400  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tests = get_tests_df(df)\n",
    "\n",
    "df_tests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01937a6-db1d-4950-b8a4-01b6aabd8131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
